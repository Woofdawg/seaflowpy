{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full functionality of `seaflowpy` can be found through the various submodules, e.g. `seaflowpy.db`, `seaflowpy.evt`. However, for convenience a few of the most commonly-used functions and classes are exposed at the package level.\n",
    "\n",
    "* **seaflowpy.EVT**  \n",
    "Class for EVT particle data\n",
    "\n",
    "* **seaflowpy.find_evt_files**  \n",
    "Function to recursively find EVT/OPP file paths within a directory\n",
    "\n",
    "The code below will use the test dataset in this repository at `./tests/testcruise/`. The files in this directory hold raw EVT data, but in this example workflow we'll treat the files as though they actually contain filtered OPP data. For example, we may have already filtered EVT to OPP data on the command-line with `filterevt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note on terminology: In this package the phrase EVT can have two subtley different meanings.  \n",
    "\n",
    "* Any binary file or Python data structure which holds SeaFlow particle data, regardless of whether raw or filtered.\n",
    "* In the context of a filtering workflow, EVT refers to the raw, unfocused/unfiltered version of particle data, distinct from OPP data which refers to the filtered/focused particles.  \n",
    "\n",
    "When filtering, we talk about converting EVT data to OPP data. We may read a raw EVT file into Python as a `seaflowpy.EVT` object and the raw particle data is stored as a pandas DataFrame in the `EVT.evt` attribute. We then filter the raw particle data with `seaflowpy.EVT.filter` and this filtered particle data is accessible as a pandas DataFrame in the `EVT.opp` atttribute. This is essentially what `filterevt` does.\n",
    "\n",
    "But when we read filtered OPP files from disk, `seaflowpy.EVT` treats them in the same way it would treat reading raw EVT files. Particle data is stored in the new `EVT` object as a pandas DataFrame in the `EVT.evt` attribute (even though we know that this is the OPP data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaflowpy as sfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./tests/testcruise/2014_185/2014-07-04T00-00-02+00-00',\n",
       " './tests/testcruise/2014_185/2014-07-04T00-03-02+00-00.gz',\n",
       " './tests/testcruise/2014_185/2014-07-04T00-06-02+00-00',\n",
       " './tests/testcruise/2014_185/2014-07-04T00-09-02+00-00',\n",
       " './tests/testcruise/2014_185/2014-07-04T00-12-02+00-00']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opp_files = sfp.find_evt_files(\"./tests/testcruise\")\n",
    "opp_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the EVT files into memory. In many cases we don't plan on using all 10 channels of particle data, so here we'll select only the channels (columns) we care about. This can significantly speed up data import when transforming (exponentiating log data) and lowers the memory footprint.\n",
    "\n",
    "Note, some of the files are unreadable, which is normal and even expected in a real cruise, so we'll catch and print any errors with try/except."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time',\n",
       " 'pulse_width',\n",
       " 'D1',\n",
       " 'D2',\n",
       " 'fsc_small',\n",
       " 'fsc_perp',\n",
       " 'fsc_big',\n",
       " 'pe',\n",
       " 'chl_small',\n",
       " 'chl_big']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The possible column names to choose from\n",
    "sfp.EVT.all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tests/testcruise/2014_185/2014-07-04T00-06-02+00-00 File is empty\n",
      "./tests/testcruise/2014_185/2014-07-04T00-09-02+00-00 File has incorrect number of data bytes. Expected 960000, saw 236\n",
      "./tests/testcruise/2014_185/2014-07-04T00-12-02+00-00 File has invalid particle count header\n"
     ]
    }
   ],
   "source": [
    "opps = []\n",
    "for f in opp_files:\n",
    "    try:\n",
    "        opps.append(sfp.EVT(f, transform=True, columns=[\"fsc_small\", \"chl_small\", \"pe\"]))\n",
    "    except sfp.errors.EVTFileError as e:\n",
    "        print \"{} {}\".format(f, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have some EVT objects in `opps`. Let's take a look at the pandas DataFrame of particle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40000 entries, 0 to 39999\n",
      "Data columns (total 3 columns):\n",
      "fsc_small    40000 non-null float64\n",
      "pe           40000 non-null float64\n",
      "chl_small    40000 non-null float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "opps[0].evt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fsc_small</th>\n",
       "      <th>pe</th>\n",
       "      <th>chl_small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.192991</td>\n",
       "      <td>1.530514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.055943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.128752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.625772</td>\n",
       "      <td>2.488267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.342477</td>\n",
       "      <td>2.178271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fsc_small        pe  chl_small\n",
       "0          1  1.192991   1.530514\n",
       "1          1  1.000000   2.055943\n",
       "2          1  1.000000   2.128752\n",
       "3          1  1.625772   2.488267\n",
       "4          1  1.342477   2.178271"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opps[0].evt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the DataFrames for each file separately, or we can combine the DataFrames into one object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80000 entries, 0 to 39999\n",
      "Data columns (total 3 columns):\n",
      "fsc_small    80000 non-null float64\n",
      "pe           80000 non-null float64\n",
      "chl_small    80000 non-null float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "opp_df = pd.concat([o.evt for o in opps])\n",
    "opp_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
